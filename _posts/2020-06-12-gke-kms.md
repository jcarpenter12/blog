---
layout: post
title: "Securing Secrets on Google Kubernetes Engine Using Cloud Build and Google’s Key Management Service (KMS) - Part 1 Building the Infrastructure with Terraform
"
thumb_image: "documentation/00_cover.PNG"
tags: [gcp, kubernetes, gke, encryption, kms, terraform, CI/CD]
---

{% include image.html path="documentation/00_cover.PNG" path-detail="documentation/00_cover.PNG" alt="Chalk intro" %}

Over these next few posts I will go over the process for deploying and securing apps on GKE.

### Purpose
Kubernetes is a widely used framework used to run and manage containerised applications built using docker. Applications often require access to sensitive information, such as passwords or API keys that need to be stored on the cluster in ‘secrets’ (more info [here](https://kubernetes.io/docs/concepts/configuration/secret/)). By default Google encrypts all customer content at rest but this still may not be secure enough for many applications, the reason being that the secrets are stored in the Kubernetes etcd ( a key value store used to store data for the cluster) on the master node. If the etcd is accessed it means that the attacker would have access to the same secrets as being used by the applications that run on the cluster. This series of posts will go over how to enable application layer encryption on a GKE cluster and build a CI/CD pipeline using cloud build in order to store and deploy secrets stored in google secrets manager to the cluster.

### Overview
Application layer encryption on GKE involves using a process known as Envelope Encryption in order to secure secrets in the etcd. A key is stored locally on the etcd known as a DEK (Data Encryption Key) that is used to encrypt the secrets. This DEK itself is also encrypted itself using a KEK (Key Encryption Key), crucially this key is not stored on the etcd or on the kubernetes master node API but instead is stored in a remote Key Management System (in this example I am using Google’s own KMS service but other vendors can be used such as Hashicorp’s Vault). The advantage of this is that it ensures that the secrets stored on the etcd are encrypted and that if an attacker were to gain access to the kubernetes master node and the etcd they would still not have access to the keys stored in KMS in order to decrypt those secrets. Other advantages of using KMS include the ability to rotate keys and ‘Crypto Shredding’, the process in which a key is removed from the key chain meaning that the DEK is no longer able to be decrypted rendering the cluster applications useless if it were compromised.

### Prerequisites
* A google cloud project with access to set up and create service accounts and control IAM roles
* A basic understanding of Terraform
* A basic understanding of Kubernetes

### Setting up the GKE cluster and KMS Key Ring Using Terraform
For this post I will be using Terraform in order to set up and manage the required infrastructure for running the applications on Kubernetes on GCP. Terraform is an open source infrastructure as code application that makes it simple to build repeatable pipelines that allow users to set up and tear down resources quickly. Some more info and a guide to setting it up can be found [here](https://www.terraform.io/intro/index.html).

### Creating a Service Account for Terraform
As Terraform is used to manage infrastructure in the cloud it requires access to services that most users will not require and as such it is good practice to use a separate service account for it.
* In the drop down menu in the cloud console select ‘I AM Admin’ > ‘Service Accounts’ > ‘Create Service Account’

{% include image.html path="documentation/01_tf_sa.png" path-detail="documentation/01_tf_sa.png" alt="Terraform Service Account" %}

### Enabling APIs
In order to run the terraform scripts the following APIs need to be enabled
* Cloud Key Management Service (KMS) API
* Kubernetes Engine API
* Cloud Build
* Secret Manager

{% include image.html path="documentation/02_enable_api.png" path-detail="documentation/02_enable_api.png" alt="Terraform Service Account" %}

### Terraform

#### Terraform State GCS Bucket
When using terraform locally by default it will save your state (more info [here](https://www.terraform.io/docs/state/index.html)) to your machine in a file named `terraform.tfstate`, this is okay when you are the sole owner of the the project but in a real world situation it is best that these files are stored remotely in GCS so that other users can run the terraform scripts and retrieve the current state of the environment.

As this will be outside of the terraform script to store its state this bucket should be created manually from the gui or the command line. NOTE: the name will need to be unique, so the following command will need to be changed to suit your needs

{% highlight bash %}
gsutil mb gs://jc-terraform-state
{% endhighlight %}

For this demonstration the terraform setup consists of the following scripts

* `main.tf` - the main entry point of the terraform script
* `variables.tf` - the variables definition file
* `terraform.tfvar` - Used to override the variables, this is especially useful for reusing the terraform scripts for different environments. In this example we will just use the one
* `backend_config.hcl` - Variables cannot be used within the terraform backend setup and this file can be specified at runtime in order to set this up for different environments

The source for these files can be found [here](https://github.com/jcarpenter12/gke-kms-infrastructure). You will need to update the `terraform.tfvar` and `backend_config.hcl` with your project and bucket details.

I will not go into complete detail about each of the terraform config files but below I have outlined the main.tf with comments

{% highlight terraform %}
// Setup provider
provider "google" {

  credentials = file(var.credentials)

  project = var.project
  region  = var.region
  zone    = var.zone
}

// At this time the beta is required in order to use the kms service with terraform
provider "google-beta" {

  credentials = file(var.credentials)

  project = var.project
  region  = var.region
  zone    = var.zone
}

terraform {
  backend "gcs" {}
}
// Used to get the project number so the gke account used to set up the cluster
// can be assigned permissons for the application layer encryption
data "google_project" "project" {
}

// Create a kms key ring to store the key
resource "google_kms_key_ring" "key_ring" {
  project  = var.project
  name     = "${var.env}-gke-key-ring"
  location = var.region
}

// Create the crypto key within the newly generated key ring
resource "google_kms_crypto_key" "kube_secrets_key" {
  name     = "${var.env}_gke_secrets_key"
  key_ring = google_kms_key_ring.key_ring.self_link
}

// The service account used to spin up the cluster requires access to the
// crypto key above in order to apply it to the gke cluster
resource "google_project_iam_binding" "gke-sa-role-kms" {
  role    = "roles/cloudkms.cryptoKeyEncrypterDecrypter"
  members = [
   "serviceAccount:service-${data.google_project.project.number}@container-engine-robot.iam.gserviceaccount.com"
  ]
}

//Enable Cloud Build to Access the Secret Manager for deploying secrets
resource "google_project_iam_binding" "cb-sa-role-sm" {
  role    = "roles/secretmanager.secretAccessor"
  members = [
   "serviceAccount:${data.google_project.project.number}@cloudbuild.gserviceaccount.com"
  ]
}

//Enable Cloud Build to Access the GKE Cluster to Deploy Apps
resource "google_project_iam_binding" "cb-sa-role-gke" {
  role    = "roles/container.developer"
  members = [
   "serviceAccount:${data.google_project.project.number}@cloudbuild.gserviceaccount.com"
  ]
}

// Create k8s cluster
resource "google_container_cluster" "primary" {
  provider = google-beta
  name     = var.cluster_name
  location = var.region
  initial_node_count = var.initial_node_count

  // this enables application layer encryption on the gke cluster and points to
  // the key used to encrypt secrets
  database_encryption {
    state = "ENCRYPTED"
    key_name = google_kms_crypto_key.kube_secrets_key.self_link
  }

  master_auth {
    username = ""
    password = ""

    client_certificate_config {
      issue_client_certificate = false
    }
  }

  node_config {

     oauth_scopes = [
      "https://www.googleapis.com/auth/logging.write",
      "https://www.googleapis.com/auth/monitoring",
      "https://www.googleapis.com/auth/devstorage.read_only",
    ]

    preemptible  = var.preemptible
    machine_type = var.machine_type

    metadata = {
      disable-legacy-endpoints = "true"
    }
  }

  depends_on = [google_kms_crypto_key.kube_secrets_key,google_project_iam_binding.gke-sa-role-kms]
}{% endhighlight %}


#### Running the Terraform Script
{% highlight bash %}
cd terraform/
terraform init
# This will display the deployment plan for the script
terraform plan
# This will apply the script and create the resources in your project
terraform apply
{% endhighlight %}

Once that has been run go to the Cloud Console and you should see that the cluster is up and running and that the cryptographic key has been created. In the next part of this blog I will go over writing an application and deploying it to this newly created cluster.
